{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9215db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import polars as pl\n",
    "import Enum_data as ed\n",
    "pl.Config.set_tbl_rows(1000)\n",
    "from persiantools import characters, digits\n",
    "import sqlite3\n",
    "\n",
    "import general_functions as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47e7352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(url: str, table: int):\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:143.0) Gecko/20100101 Firefox/143.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Origin': 'https://www.codal.ir',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.codal.ir/',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'Cookie': 'TS018fb0f7=01f9930bd2e2675d04882f623c888052df60031e7775d8e3c459dc4cb96bf8e870e0a9bf0e0eedff68bcce23fd9701c7a7fc0855c4; Unknown=1076170924.20480.0000'\n",
    "    }\n",
    "    response = requests.request(\"GET\", url)\n",
    "    statement = response.text\n",
    "    pattern = r\"var datasource = (.*?});\"\n",
    "    match = re.search(pattern, statement)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "    records = []\n",
    "    records.append(\n",
    "        (statement, text))\n",
    "    for _, data in records:\n",
    "        continue\n",
    "    items = json.loads(data)['sheets']\n",
    "\n",
    "    if isinstance(table, list):\n",
    "        cells = []\n",
    "        for t in table:\n",
    "            raw_cells = items[0]['tables'][t]['cells']\n",
    "            cells.append([(i['columnSequence'], i['rowSequence'], i['value'], i['periodEndToDate']) for i in raw_cells])\n",
    "        return [x for xs in cells for x in xs]\n",
    "    \n",
    "    cells = items[0]['tables'][table]['cells']\n",
    "    return [(i['columnSequence'], i['rowSequence'], i['value'], i['periodEndToDate']) for i in cells]\n",
    "\n",
    "def create_dict_dataframes(url: str, date: int, report_type: str) -> dict:\n",
    "    all_data ={'report_last_year': pl.DataFrame(),\n",
    "            'report_this_year': pl.DataFrame(),\n",
    "            'est_remain': pl.DataFrame(),\n",
    "            'est_next_year': pl.DataFrame()}\n",
    "\n",
    "    cells_tuples = get_table(url, ed.tabels[report_type].value)\n",
    "    dates = sorted(list(set([i[-1] for i in cells_tuples if i[-1] != ''])))\n",
    "           \n",
    "    for date_ in dates:\n",
    "        filtered_cells = [(i[0], i[1], i[2]) for i in cells_tuples if i[-1] == '' or i[-1] == (date_)]\n",
    "        df = pl.from_records(filtered_cells, schema=[\"col\", \"row\", \"value\"], orient=\"row\")\n",
    "        df = df.pivot(values=\"value\", on=\"col\", index=\"row\").sort(\"row\")\n",
    "        df = df.with_columns(pl.col('1').map_elements(characters.ar_to_fa, return_dtype=pl.String))\n",
    "\n",
    "        if report_type == 'Operational':\n",
    "            if(df.width < 8):\n",
    "                continue\n",
    "        \n",
    "        for i, col in enumerate(df.columns):\n",
    "            cols = ed.cols[report_type].value\n",
    "            value = df[col][0]        # value from first row\n",
    "            if(isinstance(value, str)):\n",
    "                for val in value.split():\n",
    "                    if'/' in val:\n",
    "                        num = int(val.replace('/', ''))\n",
    "                        next_cols = df.columns[i : i + cols + 1]\n",
    "                        cols_to_select = ['1','2', *next_cols] if report_type in ['Operational'] else ['1', *next_cols]\n",
    "                        if num < date :\n",
    "                            all_data['report_last_year'] = df.select(cols_to_select)\n",
    "                            all_data['report_last_year'] = all_data['report_last_year'].with_row_index(\"row\")\n",
    "                        elif num == date :\n",
    "                            all_data['report_this_year'] = df.select(cols_to_select)\n",
    "                            all_data['report_this_year'] = all_data['report_this_year'].with_row_index(\"row\")\n",
    "                        else:\n",
    "                            if(val[:4] == str(date)[:4]):\n",
    "                                all_data['est_remain'] = df.select(cols_to_select)\n",
    "                                all_data['est_remain'] = all_data['est_remain'].with_row_index(\"row\")\n",
    "                            else:\n",
    "                                all_data['est_next_year'] = df.select(cols_to_select)\n",
    "                                all_data['est_next_year'] = all_data['est_next_year'].with_row_index(\"row\")\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad7b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_operational_dataframe(symbol: str, url: str, date: int, period: int, publish: int):\n",
    "    all_data = create_dict_dataframes(url, date, 'Operational')\n",
    "    for name, df in all_data.items():\n",
    "        df = df.rename({c: str(i) for i, c in enumerate(df.columns)})\n",
    "        df = df.rename({'0': 'row'})\n",
    "        table_date = [d for d in str(df[df.columns[3]][0]).split() if '/' in d][0]\n",
    "        df_internal = df.clone()\n",
    "        idx_internal = df_internal.filter(df_internal['1'] == \"فروش داخلی:\")['row'][0]\n",
    "        idx_total_internal = df_internal.filter(df_internal['1'] == \"جمع فروش داخلی\")['row'][0]\n",
    "        df_internal = df_internal.filter(df_internal['row'] > idx_internal, df_internal['row'] < idx_total_internal-1)[['1','2']]\n",
    "        df_internal=df_internal.with_columns(pl.lit(\"داخلی\").alias(\"3\"))\n",
    "        df_export=df.clone()\n",
    "        idx_export = df_export.filter(df_export['1'] == \"فروش صادراتی:\")['row'][0]\n",
    "        idx_total_export = df_export.filter(df_export['1'] == \"جمع فروش صادراتی\")['row'][0]\n",
    "        df_export = df_export.filter(df_export['row']>idx_export ,df_export['row']<idx_total_export -1)[['1','2']]\n",
    "        df_export = df_export.with_columns(pl.lit(\"صادراتی\").alias('3'))\n",
    "        df_products = pl.concat([df_internal,df_export])\n",
    "        for i in df[0].rows(named=True):\n",
    "            for k, v in i.items():\n",
    "                if '/' in str(v):\n",
    "                    col_num_production = k\n",
    "                    dummy_data = df[col_num_production:str(int(col_num_production)+2)]\n",
    "                    dummy_data = dummy_data.insert_column(0, df['row'])\n",
    "                            \n",
    "                    sales_internal = dummy_data.filter(dummy_data['row'] > idx_internal, dummy_data['row'] < idx_total_internal-1)\n",
    "                    sales_export = dummy_data.filter(dummy_data['row']>idx_export ,dummy_data['row']<idx_total_export -1)\n",
    "                    sales_products = pl.concat([sales_internal, sales_export])               \n",
    "                    \n",
    "\n",
    "                    #Rename columns to range(0,1,...)\n",
    "                    sales_products = sales_products.rename(dict(zip(sales_products.columns, map(str, range(len(sales_products.columns))))))\n",
    "                    #If \"\" is in the dataframe\n",
    "                    if gf.has_empty_string(sales_products):\n",
    "                        continue\n",
    "                    #Convert string to Int from Col 1 to end\n",
    "                    sales_products = sales_products.with_columns([pl.col(sales_products.columns).cast(pl.Int32)])\n",
    "                    # concat label and values\n",
    "                    df_products = df_products.rename({c: \"_\" + c for c in df_products.columns})\n",
    "                    \n",
    "                    data = pl.concat([df_products, sales_products], how=\"horizontal\")\n",
    "                \n",
    "                    data.columns = [str(i) for i in range(data.width)]\n",
    "                    data = data.insert_column(0, pl.lit(symbol).alias(\"Symbol\"))\n",
    "                    data = data.insert_column(1, pl.lit(int(digits.fa_to_en(table_date).replace('/', ''))).alias(\"Date\"))\n",
    "                    data = data.insert_column(2, pl.lit(period).alias(\"Period\"))\n",
    "                    data = data.insert_column(3, pl.lit(publish).alias(\"Publish\"))\n",
    "                    data = data.rename({\n",
    "                        \"0\": \"Product\",\n",
    "                        \"1\": \"Unit\",\n",
    "                        \"2\": \"Type\",\n",
    "                        \"3\":\"Production\",\n",
    "                        \"4\":\"Sales\",\n",
    "                        \"5\":\"Price\"\n",
    "                    })\n",
    "                    all_data[name] = data\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71b15cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_db_format(df: pl.DataFrame, report_type: str) -> pl.DataFrame:\n",
    "    conn=sqlite3.connect(\"codal.sqlite\")\n",
    "    names = ['Symbol', 'Product', 'Type', 'Unit']\n",
    "    col_names = ['key','Symbol_id','Date','Period', 'Publish','Product_id','Type_id','Unit_id','Production','Sales','Price']\n",
    "    for name in names:\n",
    "        rows = conn.execute(f\"SELECT name, id FROM {name}\").fetchall()\n",
    "        lookup = {key: value for key, value in rows}\n",
    "        df = df.with_columns(pl.col(f\"{name}\").replace(lookup).alias(f\"{name}_id\"))\n",
    "    key_df = df.with_columns((pl.col(\"Date\").cast(pl.Utf8)+ pl.col(\"Symbol_id\").cast(pl.Utf8)+pl.col(\"Product_id\").cast(pl.Utf8)+pl.col(\"Type_id\").cast(pl.Utf8)).alias(\"key\").cast(pl.Int64))\n",
    "    key_df = key_df[col_names]\n",
    "    key_df = key_df.with_columns(pl.all().cast(pl.Int64))\n",
    "    return key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "symbol = \"فخوز\"\n",
    "financial_year = 14031230\n",
    "report_type = ed.names.Operational.value\n",
    "#----------------------------------------\n",
    "\n",
    "sheet_num = ed.sheets[report_type].value\n",
    "table = ed.tabels[report_type].value\n",
    "reports = gf.get_results(symbol=str, parse_date=str, report_type=str, sheet_num= int ,sort= bool )\n",
    "#reports\n",
    "date = 14030930\n",
    "period = int(reports[date]['period'])\n",
    "publish = int(reports[date]['publish'])\n",
    "url = reports[date]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9e31a05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m get_results(symbol, \u001b[43mparse_date\u001b[49m, report_type, sheet_num ,sort)\n",
      "\u001b[31mNameError\u001b[39m: name 'parse_date' is not defined"
     ]
    }
   ],
   "source": [
    "get_results(symbol, parse_date, report_type, sheet_num ,sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba854248",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = create_operational_dataframe(symbol, url, date, period, publish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b4796",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_data['report_last_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_df_db_format(all_data['report_this_year'],report_type)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
